#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë°ì´í„° êµ¬ì¡° ë¶„ì„ ë„êµ¬ (í…ìŠ¤íŠ¸ ê¸°ë°˜)
train_diffusion_manip_seq_joints24.p íŒŒì¼ì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ ë¶„ì„
"""

import joblib
import numpy as np
from collections import defaultdict, Counter

def print_header(title):
    """í—¤ë” ì¶œë ¥"""
    print(f"\n{'='*80}")
    print(f"ğŸ” {title}")
    print(f"{'='*80}")

def print_section(title):
    """ì„¹ì…˜ ì¶œë ¥"""
    print(f"\nğŸ“Š {title}")
    print(f"{'-'*60}")

def analyze_data_structure(data_path):
    """ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
    print_header("ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì‹œì‘")
    
    print("ğŸ”„ ë°ì´í„° ë¡œë”© ì¤‘...")
    data = joblib.load(data_path)
    
    print(f"âœ… ë¡œë”© ì™„ë£Œ!")
    print(f"   ğŸ“ íŒŒì¼: {data_path}")
    print(f"   ğŸ“Š ë°ì´í„° íƒ€ì…: {type(data)}")
    print(f"   ğŸ“ˆ ì „ì²´ ì‹œí€€ìŠ¤ ê°œìˆ˜: {len(data)}")
    
    return data

def analyze_field_shapes(data):
    """ê° í•„ë“œì˜ shape ì •ë³´ ë¶„ì„"""
    print_section("í•„ë“œë³„ Shape ì •ë³´")
    
    sample = data[0]
    print(f"ğŸ”¬ ìƒ˜í”Œ ì‹œí€€ìŠ¤: {sample['seq_name']}")
    print(f"ğŸ“ ì´ í•„ë“œ ê°œìˆ˜: {len(sample)}")
    
    print(f"\n{'í•„ë“œëª…':<20} {'Shape':<20} {'dtype':<15} {'í¬ê¸°':<10} {'íƒ€ì…'}")
    print(f"{'-'*80}")
    
    field_info = {}
    for key, value in sample.items():
        if isinstance(value, np.ndarray):
            field_info[key] = {
                'shape': value.shape,
                'dtype': str(value.dtype),
                'size': value.size,
                'ndim': value.ndim
            }
            print(f"{key:<20} {str(value.shape):<20} {str(value.dtype):<15} {value.size:<10} numpy.ndarray")
        else:
            field_info[key] = {
                'type': type(value).__name__,
                'value': str(value)
            }
            print(f"{key:<20} {'-':<20} {'-':<15} {'-':<10} {type(value).__name__}")
    
    return field_info

def analyze_sequence_statistics(data):
    """ì‹œí€€ìŠ¤ í†µê³„ ë¶„ì„"""
    print_section("ì‹œí€€ìŠ¤ í†µê³„ ë¶„ì„")
    
    subjects = set()
    objects = set()
    seq_lengths = []
    genders = []
    
    print("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    for seq_data in data.values():
        seq_name = seq_data['seq_name']
        parts = seq_name.split('_')
        
        if len(parts) >= 2:
            subjects.add(parts[0])
            objects.add(parts[1])
        
        seq_lengths.append(seq_data['trans'].shape[0])
        gender_val = seq_data['gender']
        if isinstance(gender_val, np.ndarray):
            gender_val = gender_val.item()  # numpy scalarì„ Python ê°’ìœ¼ë¡œ ë³€í™˜
        genders.append(gender_val)
    
    seq_lengths = np.array(seq_lengths)
    gender_counts = Counter(genders)
    
    print(f"âœ… ê¸°ë³¸ í†µê³„:")
    print(f"   ğŸ‘¥ í”¼í—˜ì ìˆ˜: {len(subjects)}")
    print(f"   ğŸ“¦ ê°ì²´ ì¢…ë¥˜ ìˆ˜: {len(objects)}")
    print(f"   â±ï¸  í‰ê·  ì‹œí€€ìŠ¤ ê¸¸ì´: {np.mean(seq_lengths):.1f} frames")
    print(f"   â±ï¸  ìµœì†Œ ê¸¸ì´: {np.min(seq_lengths)} frames")
    print(f"   â±ï¸  ìµœëŒ€ ê¸¸ì´: {np.max(seq_lengths)} frames")
    print(f"   â±ï¸  ì¤‘ê°„ê°’: {np.median(seq_lengths):.1f} frames")
    print(f"   â±ï¸  í‘œì¤€í¸ì°¨: {np.std(seq_lengths):.1f} frames")
    
    print(f"\nğŸ‘¥ ì„±ë³„ ë¶„í¬:")
    for gender, count in gender_counts.items():
        percentage = (count / len(genders)) * 100
        print(f"   {gender}: {count}ê°œ ({percentage:.1f}%)")
    
    return {
        'subjects': sorted(subjects),
        'objects': sorted(objects),
        'seq_lengths': seq_lengths,
        'genders': genders,
        'gender_counts': gender_counts
    }

def analyze_object_distribution(data):
    """ê°ì²´ë³„ ë¶„í¬ ë¶„ì„"""
    print_section("ê°ì²´ë³„ ì‹œí€€ìŠ¤ ë¶„í¬")
    
    obj_counts = defaultdict(int)
    obj_subjects = defaultdict(set)
    
    for seq_data in data.values():
        seq_name = seq_data['seq_name']
        parts = seq_name.split('_')
        if len(parts) >= 2:
            obj_name = parts[1]
            subj_name = parts[0]
            obj_counts[obj_name] += 1
            obj_subjects[obj_name].add(subj_name)
    
    print(f"{'ê°ì²´ëª…':<15} {'ì‹œí€€ìŠ¤ ìˆ˜':<10} {'í”¼í—˜ì ìˆ˜':<10} {'í‰ê· /í”¼í—˜ì':<12}")
    print(f"{'-'*50}")
    
    total_sequences = sum(obj_counts.values())
    for obj_name in sorted(obj_counts.keys()):
        count = obj_counts[obj_name]
        subj_count = len(obj_subjects[obj_name])
        avg_per_subj = count / subj_count if subj_count > 0 else 0
        percentage = (count / total_sequences) * 100
        print(f"{obj_name:<15} {count:<10} {subj_count:<10} {avg_per_subj:<12.1f} ({percentage:.1f}%)")

def analyze_subject_distribution(data):
    """í”¼í—˜ìë³„ ë¶„í¬ ë¶„ì„"""
    print_section("í”¼í—˜ìë³„ ì‹œí€€ìŠ¤ ë¶„í¬")
    
    subj_counts = defaultdict(int)
    subj_objects = defaultdict(set)
    
    for seq_data in data.values():
        seq_name = seq_data['seq_name']
        parts = seq_name.split('_')
        if len(parts) >= 2:
            subj_name = parts[0]
            obj_name = parts[1]
            subj_counts[subj_name] += 1
            subj_objects[subj_name].add(obj_name)
    
    print(f"{'í”¼í—˜ì':<10} {'ì‹œí€€ìŠ¤ ìˆ˜':<10} {'ê°ì²´ ìˆ˜':<10} {'í‰ê· /ê°ì²´':<12}")
    print(f"{'-'*45}")
    
    # í”¼í—˜ì ë²ˆí˜¸ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_subjects = sorted(subj_counts.keys(), key=lambda x: int(x.replace('sub', '')))
    
    for subj_name in sorted_subjects:
        count = subj_counts[subj_name]
        obj_count = len(subj_objects[subj_name])
        avg_per_obj = count / obj_count if obj_count > 0 else 0
        print(f"{subj_name:<10} {count:<10} {obj_count:<10} {avg_per_obj:<12.1f}")

def show_sample_data(data):
    """ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"""
    print_section("ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    
    sample = data[0]
    print(f"ğŸ” ì‹œí€€ìŠ¤: {sample['seq_name']}")
    print(f"ğŸ‘¤ ì„±ë³„: {sample['gender']}")
    print(f"â±ï¸  í”„ë ˆì„ ìˆ˜: {sample['trans'].shape[0]}")
    
    print(f"\nğŸ§ ì²« í”„ë ˆì„ ì¸ê°„ ë°ì´í„°:")
    print(f"   ë£¨íŠ¸ ìœ„ì¹˜ (trans): {sample['trans'][0]}")
    print(f"   ë£¨íŠ¸ íšŒì „ (root_orient): {sample['root_orient'][0]}")
    print(f"   ì²« ê´€ì ˆ í¬ì¦ˆ: {sample['pose_body'][0][:3]}")
    
    print(f"\nğŸ“¦ ì²« í”„ë ˆì„ ê°ì²´ ë°ì´í„°:")
    print(f"   ê°ì²´ ìŠ¤ì¼€ì¼: {sample['obj_scale'][0]:.6f}")
    print(f"   ê°ì²´ ìœ„ì¹˜: {sample['obj_trans'][0].flatten()}")
    print(f"   ê°ì²´ ì¤‘ì‹¬: {sample['obj_com_pos'][0]}")
    
    print(f"\nğŸ”¢ SMPL ì²´í˜• íŒŒë¼ë¯¸í„° (betas):")
    print(f"   ì „ì²´ ì°¨ì›: {sample['betas'].shape}")
    print(f"   ì²˜ìŒ 8ê°œ ê°’: {sample['betas'][0][:8]}")

def create_structure_diagram():
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ êµ¬ì¡° ë‹¤ì´ì–´ê·¸ë¨"""
    print_section("ë°ì´í„° êµ¬ì¡° ë‹¤ì´ì–´ê·¸ë¨")
    
    diagram = """
ğŸ“ train_diffusion_manip_seq_joints24.p
â”‚
â”œâ”€â”€ ğŸ“Š ì „ì²´ êµ¬ì¡°: Dict[int, Dict] (5280ê°œ ì‹œí€€ìŠ¤)
â”‚   â”œâ”€â”€ Key: 0, 1, 2, ..., 5279 (ì‹œí€€ìŠ¤ ì¸ë±ìŠ¤)
â”‚   â””â”€â”€ Value: ê° ì‹œí€€ìŠ¤ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
â”‚
â””â”€â”€ ğŸ” ê° ì‹œí€€ìŠ¤ êµ¬ì¡°:
    â”‚
    â”œâ”€â”€ ğŸ“ ë©”íƒ€ë°ì´í„°
    â”‚   â”œâ”€â”€ seq_name: str           # "sub10_clothesstand_000"
    â”‚   â”œâ”€â”€ gender: str             # "male" or "female"  
    â”‚   â””â”€â”€ betas: (1, 16)          # SMPL ì²´í˜• íŒŒë¼ë¯¸í„°
    â”‚
    â”œâ”€â”€ ğŸ”§ ë³€í™˜ ì •ë³´
    â”‚   â”œâ”€â”€ trans2joint: (3,)       # ë£¨íŠ¸â†’ê´€ì ˆ ë³€í™˜ ë²¡í„°
    â”‚   â””â”€â”€ rest_offsets: (24, 3)   # ê´€ì ˆ ì˜¤í”„ì…‹ (íœ´ì‹ í¬ì¦ˆ)
    â”‚
    â”œâ”€â”€ ğŸš¶ ì¸ê°„ ëª¨ì…˜ ë°ì´í„° (T í”„ë ˆì„)
    â”‚   â”œâ”€â”€ trans: (T, 3)           # ë£¨íŠ¸ ê´€ì ˆ ìœ„ì¹˜ (ì „ì—­ì¢Œí‘œ)
    â”‚   â”œâ”€â”€ root_orient: (T, 3)     # ë£¨íŠ¸ íšŒì „ (axis-angle)
    â”‚   â””â”€â”€ pose_body: (T, 63)      # ëª¸ì²´ í¬ì¦ˆ (21ê´€ì ˆ Ã— 3)
    â”‚
    â””â”€â”€ ğŸ“¦ ê°ì²´ ëª¨ì…˜ ë°ì´í„° (T í”„ë ˆì„)
        â”œâ”€â”€ obj_scale: (T,)         # ê°ì²´ í¬ê¸° ìŠ¤ì¼€ì¼
        â”œâ”€â”€ obj_trans: (T, 3, 1)    # ê°ì²´ ìœ„ì¹˜ (ì „ì—­ì¢Œí‘œ)
        â”œâ”€â”€ obj_rot: (T, 3, 3)      # ê°ì²´ íšŒì „ í–‰ë ¬
        â””â”€â”€ obj_com_pos: (T, 3)     # ê°ì²´ ì¤‘ì‹¬ì  ìœ„ì¹˜

ğŸ’¡ ì£¼ìš” íŠ¹ì§•:
   â€¢ TëŠ” ê° ì‹œí€€ìŠ¤ë§ˆë‹¤ ë‹¤ë¦„ (29~652 í”„ë ˆì„)
   â€¢ ëª¨ë“  ì¢Œí‘œëŠ” ì „ì—­ ì¢Œí‘œê³„ ê¸°ì¤€
   â€¢ SMPL ëª¨ë¸ ê¸°ë°˜ ì¸ê°„ í‘œí˜„ (24ê°œ ê´€ì ˆ)
   â€¢ 15ì¢…ë¥˜ ê°ì²´ Ã— 15ëª… í”¼í—˜ì ì¡°í•©
    """
    
    print(diagram)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    data_path = "processed_data/train_diffusion_manip_seq_joints24.p"
    
    print("ğŸš€ ë°ì´í„° êµ¬ì¡° ë¶„ì„ ë„êµ¬")
    print(f"ğŸ“ ëŒ€ìƒ íŒŒì¼: {data_path}")
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ êµ¬ì¡°
        data = analyze_data_structure(data_path)
        
        # 2. í•„ë“œ shape ì •ë³´
        field_info = analyze_field_shapes(data)
        
        # 3. ì‹œí€€ìŠ¤ í†µê³„
        stats = analyze_sequence_statistics(data)
        
        # 4. ê°ì²´ë³„ ë¶„í¬
        analyze_object_distribution(data)
        
        # 5. í”¼í—˜ìë³„ ë¶„í¬  
        analyze_subject_distribution(data)
        
        # 6. ìƒ˜í”Œ ë°ì´í„°
        show_sample_data(data)
        
        # 7. êµ¬ì¡° ë‹¤ì´ì–´ê·¸ë¨
        create_structure_diagram()
        
        print_header("ë¶„ì„ ì™„ë£Œ")
        print(f"âœ… ì´ {len(data)}ê°œ ì‹œí€€ìŠ¤ ë¶„ì„ ì™„ë£Œ")
        print(f"ğŸ“Š {len(stats['subjects'])}ëª… í”¼í—˜ì, {len(stats['objects'])}ì¢…ë¥˜ ê°ì²´")
        print(f"â±ï¸  í‰ê·  {np.mean(stats['seq_lengths']):.1f} í”„ë ˆì„")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
